---
title: "Deep Lagrangian Propagation in Graph Neural Networks"
collection: publications
permalink: /publication/2020-07-17-grl
excerpt: 'ICML20 - GRL+ Workshop paper - DeepLPGNN'
date: 2020-07-17
venue: 'ICML20 - GRL+ Workshop paper'
paperurl: 'https://grlplus.github.io/papers/51.pdf'
citation: 'Matteo Tiezzi, Giuseppe Marra, Stefano Melacci and Marco Maggini  (2020). &quot;Deep Lagrangian Propagation in Graph Neural Networks &quot; <i>ICML20 - GRL+ Workshop</i>'
---

Graph Neural Networks (Scarselli et al., 2009) exploit an iterative diffusion procedure to compute the node states as the fixed point of the trainable state transition function. In this paper, we show how to cast this scheme as a constrained optimization problem, thus avoiding the unfolding procedure required for the computation of the fixed point. This is done by searching for saddle
points of the Lagrangian function in the space of the weights, state variables and Lagrange multipliers. The proposed approach shows state-of-the-art performance in multiple standard  benchmarks in graph domains.

[Download paper here](https://grlplus.github.io/papers/51.pdf)

[Have a look at the poster video!](https://slideslive.com/38931504/deep-lagrangian-propagation-in-graph-neural-networks)

Recommended citation: 
Matteo Tiezzi, Giuseppe Marra, Stefano Melacci and Marco Maggini (2020). "Deep Lagrangian Propagation in Graph Neural Networks" <i>ICML20 - GRL+ Workshop</i>.